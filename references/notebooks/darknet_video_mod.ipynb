{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/e/Projects/skripsi\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9511ba1b84c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "# %cd '/mnt/e/Projects/skripsi/alexeyb-darknet'\n",
    "%cd '/mnt/e/Projects/skripsi/'\n",
    "\n",
    "from ctypes import *                                               # Import libraries\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import darknet\n",
    "# import alexeyb_darknet as dn\n",
    "# from alexeyb_darknet import darknet\n",
    "\n",
    "def convertBack(x, y, w, h):\n",
    "    xmin = int(round(x - (w / 2)))\n",
    "    xmax = int(round(x + (w / 2)))\n",
    "    ymin = int(round(y - (h / 2)))\n",
    "    ymax = int(round(y + (h / 2)))\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "\n",
    "def cvDrawBoxes(detections, img):\n",
    "    # Colored labels dictionary\n",
    "    # below is just list of colors that will be used to draw bounding box that represents the class, not the rgb value to be used to detect the objects\n",
    "    color_dict = {\n",
    "        'person' : [0, 255, 255], 'bicycle': [238, 123, 158], 'car' : [24, 245, 217], 'motorbike' : [224, 119, 227],\n",
    "        'aeroplane' : [154, 52, 104], 'bus' : [179, 50, 247], 'train' : [180, 164, 5], 'truck' : [82, 42, 106],\n",
    "        'boat' : [201, 25, 52], 'traffic light' : [62, 17, 209], 'fire hydrant' : [60, 68, 169], 'stop sign' : [199, 113, 167],\n",
    "        'parking meter' : [19, 71, 68], 'bench' : [161, 83, 182], 'bird' : [75, 6, 145], 'cat' : [100, 64, 151],\n",
    "        'dog' : [156, 116, 171], 'horse' : [88, 9, 123], 'sheep' : [181, 86, 222], 'cow' : [116, 238, 87],'elephant' : [74, 90, 143],\n",
    "        'bear' : [249, 157, 47], 'zebra' : [26, 101, 131], 'giraffe' : [195, 130, 181], 'backpack' : [242, 52, 233],\n",
    "        'umbrella' : [131, 11, 189], 'handbag' : [221, 229, 176], 'tie' : [193, 56, 44], 'suitcase' : [139, 53, 137],\n",
    "        'frisbee' : [102, 208, 40], 'skis' : [61, 50, 7], 'snowboard' : [65, 82, 186], 'sports ball' : [65, 82, 186],\n",
    "        'kite' : [153, 254, 81],'baseball bat' : [233, 80, 195],'baseball glove' : [165, 179, 213],'skateboard' : [57, 65, 211],\n",
    "        'surfboard' : [98, 255, 164],'tennis racket' : [205, 219, 146],'bottle' : [140, 138, 172],'wine glass' : [23, 53, 119],\n",
    "        'cup' : [102, 215, 88],'fork' : [198, 204, 245],'knife' : [183, 132, 233],'spoon' : [14, 87, 125],\n",
    "        'bowl' : [221, 43, 104],'banana' : [181, 215, 6],'apple' : [16, 139, 183],'sandwich' : [150, 136, 166],'orange' : [219, 144, 1],\n",
    "        'broccoli' : [123, 226, 195],'carrot' : [230, 45, 209],'hot dog' : [252, 215, 56],'pizza' : [234, 170, 131],\n",
    "        'donut' : [36, 208, 234],'cake' : [19, 24, 2],'chair' : [115, 184, 234],'sofa' : [125, 238, 12],\n",
    "        'pottedplant' : [57, 226, 76],'bed' : [77, 31, 134],'diningtable' : [208, 202, 204],'toilet' : [208, 202, 204],\n",
    "        'tvmonitor' : [208, 202, 204],'laptop' : [159, 149, 163],'mouse' : [148, 148, 87],'remote' : [171, 107, 183],\n",
    "        'keyboard' : [33, 154, 135],'cell phone' : [206, 209, 108],'microwave' : [206, 209, 108],'oven' : [97, 246, 15],\n",
    "        'toaster' : [147, 140, 184],'sink' : [157, 58, 24],'refrigerator' : [117, 145, 137],'book' : [155, 129, 244],\n",
    "        'clock' : [53, 61, 6],'vase' : [145, 75, 152],'scissors' : [8, 140, 38],'teddy bear' : [37, 61, 220],\n",
    "        'hair drier' : [129, 12, 229],'toothbrush' : [11, 126, 158]\n",
    "    }\n",
    "    \n",
    "    for detection in detections:\n",
    "        x, y, w, h = detection[2][0],\\\n",
    "            detection[2][1],\\\n",
    "            detection[2][2],\\\n",
    "            detection[2][3]\n",
    "        name_tag = str(detection[0].decode())\n",
    "        for name_key, color_val in color_dict.items():\n",
    "            if name_key == name_tag:\n",
    "                color = color_val \n",
    "                xmin, ymin, xmax, ymax = convertBack(\n",
    "                float(x), float(y), float(w), float(h))\n",
    "                pt1 = (xmin, ymin)\n",
    "                pt2 = (xmax, ymax)\n",
    "                cv2.rectangle(img, pt1, pt2, color, 1)\n",
    "                cv2.putText(img,\n",
    "                            detection[0].decode() +\n",
    "                            \" [\" + str(round(detection[1] * 100, 2)) + \"]\",\n",
    "                            (pt1[0], pt1[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                            color, 2)\n",
    "    return img\n",
    "\n",
    "\n",
    "netMain = None\n",
    "metaMain = None\n",
    "altNames = None\n",
    "\n",
    "\n",
    "def YOLO():\n",
    "   \n",
    "    global metaMain, netMain, altNames\n",
    "    # native params\n",
    "    # configPath = \"./cfg/yolov4.cfg\"                                 # Path to cfg\n",
    "    # weightPath = \"./yolov4.weights\"                                 # Path to weights\n",
    "    # metaPath = \"./cfg/coco.data\"                                    # Path to meta data\n",
    "    # custom params\n",
    "    configPath = \"/mnt/e/Projects/skripsi/alexeyb_darknet/cfg/yolov4.cfg\"                                 # Path to cfg\n",
    "    weightPath = \"/mnt/e/Projects/skripsi/alexeyb_darknet/yolov4.weights\"                                 # Path to weights\n",
    "    metaPath = \"/mnt/e/Projects/skripsi/alexeyb_darknet/cfg/coco.data\"                                    # Path to meta data\n",
    "    if not os.path.exists(configPath):                              # Checks whether file exists otherwise return ValueError\n",
    "        raise ValueError(\"Invalid config path `\" +\n",
    "                         os.path.abspath(configPath)+\"`\")\n",
    "    if not os.path.exists(weightPath):\n",
    "        raise ValueError(\"Invalid weight path `\" +\n",
    "                         os.path.abspath(weightPath)+\"`\")\n",
    "    if not os.path.exists(metaPath):\n",
    "        raise ValueError(\"Invalid data file path `\" +\n",
    "                         os.path.abspath(metaPath)+\"`\")\n",
    "    # netMain: loads config file\n",
    "    if netMain is None:                                             # Checks the metaMain, NetMain and altNames. Loads it in script\n",
    "        netMain = dn.darknet.load_net_custom(configPath.encode( \n",
    "            \"ascii\"), weightPath.encode(\"ascii\"), 0, 1)             # batch size = 1\n",
    "    # metaMain: loads the metapath, metadata coco.names\n",
    "    if metaMain is None:\n",
    "        metaMain = darknet.load_meta(metaPath.encode(\"ascii\"))\n",
    "    if altNames is None:\n",
    "        try:\n",
    "            with open(metaPath) as metaFH:\n",
    "                metaContents = metaFH.read()\n",
    "                import re\n",
    "                match = re.search(\"names *= *(.*)$\", metaContents,\n",
    "                                  re.IGNORECASE | re.MULTILINE)\n",
    "                if match:\n",
    "                    result = match.group(1)\n",
    "                else:\n",
    "                    result = None\n",
    "                try:\n",
    "                    if os.path.exists(result):\n",
    "                        with open(result) as namesFH:\n",
    "                            namesList = namesFH.read().strip().split(\"\\n\")\n",
    "                            altNames = [x.strip() for x in namesList]\n",
    "                except TypeError:\n",
    "                    pass\n",
    "        except Exception:\n",
    "            pass\n",
    "    # cap = cv2.VideoCapture(0)                                      # Uncomment to use Webcam\n",
    "    cap = cv2.VideoCapture(\"video3.mp4\")                             # Local Stored video detection - Set input video\n",
    "    frame_width = int(cap.get(3))                                   # Returns the width and height of capture video\n",
    "    frame_height = int(cap.get(4))\n",
    "    # Set out for video writer\n",
    "    out = cv2.VideoWriter(                                          # Set the Output path for video writer\n",
    "        \"./Demo/output.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 10.0,\n",
    "        (frame_width, frame_height))\n",
    "\n",
    "    print(\"Starting the YOLO loop...\")\n",
    "\n",
    "    # Create an image we reuse for each detect\n",
    "    darknet_image = darknet.make_image(frame_width, frame_height, 3) # Create image according darknet for compatibility of network\n",
    "    while True:                                                      # Load the input frame and write output frame.\n",
    "        prev_time = time.time()\n",
    "        ret, frame_read = cap.read()                                 # Capture frame and return true if frame present\n",
    "        # For Assertion Failed Error in OpenCV\n",
    "        if not ret:                                                  # Check if frame present otherwise he break the while loop\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame_read, cv2.COLOR_BGR2RGB)      # Convert frame into RGB from BGR and resize accordingly\n",
    "        frame_resized = cv2.resize(frame_rgb,\n",
    "                                   (frame_width, frame_height),\n",
    "                                   interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        darknet.copy_image_from_bytes(darknet_image,frame_resized.tobytes())                # Copy that frame bytes to darknet_image\n",
    "\n",
    "        detections = darknet.detect_image(netMain, metaMain, darknet_image, thresh=0.25)    # Detection occurs at this line and return detections, for customize we can change the threshold.                                                                                   \n",
    "        image = cvDrawBoxes(detections, frame_resized)               # Call the function cvDrawBoxes() for colored bounding box per class\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        print(1/(time.time()-prev_time))\n",
    "        cv2.imshow('Demo', image)                                    # Display Image window\n",
    "        cv2.waitKey(3)\n",
    "        out.write(image)                                             # Write that frame into output video\n",
    "    cap.release()                                                    # For releasing cap and out. \n",
    "    out.release()\n",
    "    print(\":::Video Write Completed\")\n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    YOLO()                                                           # Calls the main function YOLO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Projects\\skripsi\\alexeyb_darknet_cuda_working_by_vs\\build\\darknet\\x64\n",
      "CAP_PROP_FORMAT 0.0\n",
      "CAP_PROP_FOURCC 828601953.0\n",
      "<class 'int'>\n",
      "a\n",
      "v\n",
      "c\n",
      "1\n",
      "avc1\n",
      "CAP_PROP_POS_MSEC 0.0\n",
      "CAP_PROP_AVI_RATIO 7.8125e-05\n",
      "CAP_PROP_FRAME_WIDTH 1280.0\n",
      "CAP_PROP_FRAME_HEIGHT 720.0\n",
      "CAP_PROP_FPS 25.0\n",
      "CAP_PROP_FRAME_COUNT 531.0\n",
      "CAP_PROP_MODE 0.0\n",
      "CAP_PROP_BRIGHTNESS 0.0\n",
      "CAP_PROP_CONTRAST 0.0\n",
      "CAP_PROP_SATURATION 0.0\n",
      "CAP_PROP_HUE 0.0\n",
      "CAP_PROP_GAIN 0.0\n",
      "CAP_PROP_EXPOSURE 0.0\n",
      "CAP_PROP_CONVERT_RGB 0.0\n",
      "CAP_PROP_RECTIFICATION 0.0\n"
     ]
    }
   ],
   "source": [
    "%cd \"/Projects/skripsi/alexeyb_darknet_cuda_working_by_vs/build/darknet/x64/\"\n",
    "# %ls\n",
    "import cv2\n",
    "cap = cv2.VideoCapture(\"./Input/video3.mp4\")\n",
    "print(\"CAP_PROP_FORMAT\", cap.get(cv2.CAP_PROP_FORMAT))\n",
    "\n",
    "print(\"CAP_PROP_FOURCC\", cap.get(cv2.CAP_PROP_FOURCC))\n",
    "fourcc = cap.get(cv2.CAP_PROP_FOURCC)\n",
    "fourcc = int(fourcc)\n",
    "fourcc_str = chr(fourcc & 255) + chr((fourcc >> 8) & 255) + chr((fourcc >> 16) & 255) + chr((fourcc >> 24) & 255)\n",
    "print(fourcc_str)\n",
    "\n",
    "print(\"CAP_PROP_POS_MSEC\", cap.get(cv2.CAP_PROP_POS_MSEC))\n",
    "print(\"CAP_PROP_AVI_RATIO\", cap.get(cv2.CAP_PROP_POS_AVI_RATIO))\n",
    "print(\"CAP_PROP_FRAME_WIDTH\", cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(\"CAP_PROP_FRAME_HEIGHT\", cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(\"CAP_PROP_FPS\", cap.get(cv2.CAP_PROP_FPS))\n",
    "print(\"CAP_PROP_FRAME_COUNT\", cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"CAP_PROP_MODE\", cap.get(cv2.CAP_PROP_MODE))\n",
    "print(\"CAP_PROP_BRIGHTNESS\", cap.get(cv2.CAP_PROP_BRIGHTNESS))\n",
    "print(\"CAP_PROP_CONTRAST\", cap.get(cv2.CAP_PROP_CONTRAST))\n",
    "print(\"CAP_PROP_SATURATION\", cap.get(cv2.CAP_PROP_SATURATION))\n",
    "print(\"CAP_PROP_HUE\", cap.get(cv2.CAP_PROP_HUE))\n",
    "print(\"CAP_PROP_GAIN\", cap.get(cv2.CAP_PROP_GAIN))\n",
    "print(\"CAP_PROP_EXPOSURE\", cap.get(cv2.CAP_PROP_EXPOSURE))\n",
    "print(\"CAP_PROP_CONVERT_RGB\", cap.get(cv2.CAP_PROP_CONVERT_RGB))\n",
    "print(\"CAP_PROP_RECTIFICATION\", cap.get(cv2.CAP_PROP_RECTIFICATION))\n",
    "\n",
    "# CAP_PROP_POS_MSEC Current position of the video file in milliseconds or video capture timestamp.\n",
    "# CAP_PROP_POS_FRAMES 0-based index of the frame to be decoded/captured next.\n",
    "# CAP_PROP_POS_AVI_RATIO Relative position of the video file: 0 - start of the film, 1 - end of the film.\n",
    "# CAP_PROP_FRAME_WIDTH Width of the frames in the video stream.\n",
    "# CAP_PROP_FRAME_HEIGHT Height of the frames in the video stream.\n",
    "# CAP_PROP_FPS Frame rate.\n",
    "# CAP_PROP_FOURCC 4-character code of codec.\n",
    "# CAP_PROP_FRAME_COUNT Number of frames in the video file.\n",
    "# CAP_PROP_FORMAT Format of the Mat objects returned by retrieve() .\n",
    "# CAP_PROP_MODE Backend-specific value indicating the current capture mode.\n",
    "# CAP_PROP_BRIGHTNESS Brightness of the image (only for cameras).\n",
    "# CAP_PROP_CONTRAST Contrast of the image (only for cameras).\n",
    "# CAP_PROP_SATURATION Saturation of the image (only for cameras).\n",
    "# CAP_PROP_HUE Hue of the image (only for cameras).\n",
    "# CAP_PROP_GAIN Gain of the image (only for cameras).\n",
    "# CAP_PROP_EXPOSURE Exposure (only for cameras).\n",
    "# CAP_PROP_CONVERT_RGB Boolean flags indicating whether images should be converted to RGB.\n",
    "# CAP_PROP_WHITE_BALANCE Currently not supported\n",
    "# CAP_PROP_RECTIFICATION Rectification flag for stereo cameras (note: only supported by DC1394 v 2.x backend currently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Projects\\skripsi\\alexeyb_darknet_cuda_working_by_vs\\build\\darknet\\x64\n",
      "avc1\n"
     ]
    }
   ],
   "source": [
    "%cd \"/Projects/skripsi/alexeyb_darknet_cuda_working_by_vs/build/darknet/x64/\"\n",
    "# %ls\n",
    "import cv2\n",
    "cap = cv2.VideoCapture(\"./Input/video3.mp4\")\n",
    "fourcc = cap.get(cv2.CAP_PROP_FOURCC)\n",
    "fourcc = int(fourcc)\n",
    "fourcc_str = chr(fourcc & 255) + chr((fourcc >> 8) & 255) + chr((fourcc >> 16) & 255) + chr((fourcc >> 24) & 255)\n",
    "print(fourcc_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"/Projects/skripsi/alexeyb_darknet_cuda_working_by_vs/build/darknet/x64/\"\n",
    "import darknet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
