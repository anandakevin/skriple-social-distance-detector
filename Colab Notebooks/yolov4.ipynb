{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring cuDNN on Colab for YOLOv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA: Let's check that Nvidia CUDA drivers are already pre-installed and which version is it.\n",
    "!/usr/local/cuda/bin/nvcc --version\n",
    "# We need to install the correct cuDNN according to this output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the number depending on what GPU is listed above, under NVIDIA-SMI > Name.\n",
    "# Tesla K80: 30\n",
    "# Tesla P100: 60\n",
    "# Tesla T4: 75\n",
    "%env compute_capability=75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Installing Darknet for YOLOv4 on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/\n",
    "%rm -rf darknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we clone the fork of darknet maintained by roboflow\n",
    "#small changes have been made to configure darknet for training\n",
    "!git clone https://github.com/roboflow-ai/darknet.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/darknet/\n",
    "%rm Makefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab occasionally shifts dependencies around, at the time of authorship, this Makefile works for building Darknet on Colab\n",
    "\n",
    "%%writefile Makefile\n",
    "GPU=1\n",
    "CUDNN=1\n",
    "CUDNN_HALF=0\n",
    "OPENCV=1\n",
    "AVX=0\n",
    "OPENMP=0\n",
    "LIBSO=1\n",
    "ZED_CAMERA=0\n",
    "ZED_CAMERA_v2_8=0\n",
    "\n",
    "# set GPU=1 and CUDNN=1 to speedup on GPU\n",
    "# set CUDNN_HALF=1 to further speedup 3 x times (Mixed-precision on Tensor Cores) GPU: Volta, Xavier, Turing and higher\n",
    "# set AVX=1 and OPENMP=1 to speedup on CPU (if error occurs then set AVX=0)\n",
    "# set ZED_CAMERA=1 to enable ZED SDK 3.0 and above\n",
    "# set ZED_CAMERA_v2_8=1 to enable ZED SDK 2.X\n",
    "\n",
    "USE_CPP=0\n",
    "DEBUG=0\n",
    "\n",
    "ARCH= -gencode arch=compute_75,code=[sm_75,compute_75]\n",
    "      # -gencode arch=compute_30,code=sm_30 \\\n",
    "      # -gencode arch=compute_35,code=sm_35 \\\n",
    "      # -gencode arch=compute_50,code=[sm_50,compute_50] \\\n",
    "      # -gencode arch=compute_52,code=[sm_52,compute_52] \\\n",
    "\t    # -gencode arch=compute_61,code=[sm_61,compute_61]\n",
    "\n",
    "OS := $(shell uname)\n",
    "\n",
    "# Tesla V100\n",
    "# ARCH= -gencode arch=compute_70,code=[sm_70,compute_70]\n",
    "\n",
    "# GeForce RTX 2080 Ti, RTX 2080, RTX 2070, Quadro RTX 8000, Quadro RTX 6000, Quadro RTX 5000, Tesla T4, XNOR Tensor Cores\n",
    "# ARCH= -gencode arch=compute_75,code=[sm_75,compute_75]\n",
    "\n",
    "# Jetson XAVIER\n",
    "# ARCH= -gencode arch=compute_72,code=[sm_72,compute_72]\n",
    "\n",
    "# GTX 1080, GTX 1070, GTX 1060, GTX 1050, GTX 1030, Titan Xp, Tesla P40, Tesla P4\n",
    "# ARCH= -gencode arch=compute_61,code=sm_61 -gencode arch=compute_61,code=compute_61\n",
    "\n",
    "# GP100/Tesla P100 - DGX-1\n",
    "# ARCH= -gencode arch=compute_60,code=sm_60\n",
    "\n",
    "# For Jetson TX1, Tegra X1, DRIVE CX, DRIVE PX - uncomment:\n",
    "# ARCH= -gencode arch=compute_53,code=[sm_53,compute_53]\n",
    "\n",
    "# For Jetson Tx2 or Drive-PX2 uncomment:\n",
    "# ARCH= -gencode arch=compute_62,code=[sm_62,compute_62]\n",
    "\n",
    "\n",
    "VPATH=./src/\n",
    "EXEC=darknet\n",
    "OBJDIR=./obj/\n",
    "\n",
    "ifeq ($(LIBSO), 1)\n",
    "LIBNAMESO=libdarknet.so\n",
    "APPNAMESO=uselib\n",
    "endif\n",
    "\n",
    "ifeq ($(USE_CPP), 1)\n",
    "CC=g++\n",
    "else\n",
    "CC=gcc\n",
    "endif\n",
    "\n",
    "CPP=g++ -std=c++11\n",
    "NVCC=nvcc\n",
    "OPTS=-Ofast\n",
    "LDFLAGS= -lm -pthread\n",
    "COMMON= -Iinclude/ -I3rdparty/stb/include\n",
    "CFLAGS=-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC\n",
    "\n",
    "ifeq ($(DEBUG), 1)\n",
    "#OPTS= -O0 -g\n",
    "#OPTS= -Og -g\n",
    "COMMON+= -DDEBUG\n",
    "CFLAGS+= -DDEBUG\n",
    "else\n",
    "ifeq ($(AVX), 1)\n",
    "CFLAGS+= -ffp-contract=fast -mavx -mavx2 -msse3 -msse4.1 -msse4.2 -msse4a\n",
    "endif\n",
    "endif\n",
    "\n",
    "CFLAGS+=$(OPTS)\n",
    "\n",
    "ifneq (,$(findstring MSYS_NT,$(OS)))\n",
    "LDFLAGS+=-lws2_32\n",
    "endif\n",
    "\n",
    "ifeq ($(OPENCV), 1)\n",
    "COMMON+= -DOPENCV\n",
    "CFLAGS+= -DOPENCV\n",
    "LDFLAGS+= `pkg-config --libs opencv4 2> /dev/null || pkg-config --libs opencv`\n",
    "COMMON+= `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv`\n",
    "endif\n",
    "\n",
    "ifeq ($(OPENMP), 1)\n",
    "CFLAGS+= -fopenmp\n",
    "LDFLAGS+= -lgomp\n",
    "endif\n",
    "\n",
    "ifeq ($(GPU), 1)\n",
    "COMMON+= -DGPU -I/usr/local/cuda/include/\n",
    "CFLAGS+= -DGPU\n",
    "ifeq ($(OS),Darwin) #MAC\n",
    "LDFLAGS+= -L/usr/local/cuda/lib -lcuda -lcudart -lcublas -lcurand\n",
    "else\n",
    "LDFLAGS+= -L/usr/local/cuda/lib64 -lcuda -lcudart -lcublas -lcurand\n",
    "endif\n",
    "endif\n",
    "\n",
    "ifeq ($(CUDNN), 1)\n",
    "COMMON+= -DCUDNN\n",
    "ifeq ($(OS),Darwin) #MAC\n",
    "CFLAGS+= -DCUDNN -I/usr/local/cuda/include\n",
    "LDFLAGS+= -L/usr/local/cuda/lib -lcudnn\n",
    "else\n",
    "CFLAGS+= -DCUDNN -I/usr/local/cudnn/include\n",
    "LDFLAGS+= -L/usr/local/cudnn/lib64 -lcudnn\n",
    "endif\n",
    "endif\n",
    "\n",
    "ifeq ($(CUDNN_HALF), 1)\n",
    "COMMON+= -DCUDNN_HALF\n",
    "CFLAGS+= -DCUDNN_HALF\n",
    "ARCH+= -gencode arch=compute_70,code=[sm_70,compute_70]\n",
    "endif\n",
    "\n",
    "ifeq ($(ZED_CAMERA), 1)\n",
    "CFLAGS+= -DZED_STEREO -I/usr/local/zed/include\n",
    "ifeq ($(ZED_CAMERA_v2_8), 1)\n",
    "LDFLAGS+= -L/usr/local/zed/lib -lsl_core -lsl_input -lsl_zed\n",
    "#-lstdc++ -D_GLIBCXX_USE_CXX11_ABI=0\n",
    "else\n",
    "LDFLAGS+= -L/usr/local/zed/lib -lsl_zed\n",
    "#-lstdc++ -D_GLIBCXX_USE_CXX11_ABI=0\n",
    "endif\n",
    "endif\n",
    "\n",
    "OBJ=image_opencv.o http_stream.o gemm.o utils.o dark_cuda.o convolutional_layer.o list.o image.o activations.o im2col.o col2im.o blas.o crop_layer.o dropout_layer.o maxpool_layer.o softmax_layer.o data.o matrix.o network.o connected_layer.o cost_layer.o parser.o option_list.o darknet.o detection_layer.o captcha.o route_layer.o writing.o box.o nightmare.o normalization_layer.o avgpool_layer.o coco.o dice.o yolo.o detector.o layer.o compare.o classifier.o local_layer.o swag.o shortcut_layer.o activation_layer.o rnn_layer.o gru_layer.o rnn.o rnn_vid.o crnn_layer.o demo.o tag.o cifar.o go.o batchnorm_layer.o art.o region_layer.o reorg_layer.o reorg_old_layer.o super.o voxel.o tree.o yolo_layer.o gaussian_yolo_layer.o upsample_layer.o lstm_layer.o conv_lstm_layer.o scale_channels_layer.o sam_layer.o\n",
    "ifeq ($(GPU), 1)\n",
    "LDFLAGS+= -lstdc++\n",
    "OBJ+=convolutional_kernels.o activation_kernels.o im2col_kernels.o col2im_kernels.o blas_kernels.o crop_layer_kernels.o dropout_layer_kernels.o maxpool_layer_kernels.o network_kernels.o avgpool_layer_kernels.o\n",
    "endif\n",
    "\n",
    "OBJS = $(addprefix $(OBJDIR), $(OBJ))\n",
    "DEPS = $(wildcard src/*.h) Makefile include/darknet.h\n",
    "\n",
    "all: $(OBJDIR) backup results setchmod $(EXEC) $(LIBNAMESO) $(APPNAMESO)\n",
    "\n",
    "ifeq ($(LIBSO), 1)\n",
    "CFLAGS+= -fPIC\n",
    "\n",
    "$(LIBNAMESO): $(OBJDIR) $(OBJS) include/yolo_v2_class.hpp src/yolo_v2_class.cpp\n",
    "\t$(CPP) -shared -std=c++11 -fvisibility=hidden -DLIB_EXPORTS $(COMMON) $(CFLAGS) $(OBJS) src/yolo_v2_class.cpp -o $@ $(LDFLAGS)\n",
    "\n",
    "$(APPNAMESO): $(LIBNAMESO) include/yolo_v2_class.hpp src/yolo_console_dll.cpp\n",
    "\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) -o $@ src/yolo_console_dll.cpp $(LDFLAGS) -L ./ -l:$(LIBNAMESO)\n",
    "endif\n",
    "\n",
    "$(EXEC): $(OBJS)\n",
    "\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) $^ -o $@ $(LDFLAGS)\n",
    "\n",
    "$(OBJDIR)%.o: %.c $(DEPS)\n",
    "\t$(CC) $(COMMON) $(CFLAGS) -c $< -o $@\n",
    "\n",
    "$(OBJDIR)%.o: %.cpp $(DEPS)\n",
    "\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) -c $< -o $@\n",
    "\n",
    "$(OBJDIR)%.o: %.cu $(DEPS)\n",
    "\t$(NVCC) $(ARCH) $(COMMON) --compiler-options \"$(CFLAGS)\" -c $< -o $@\n",
    "\n",
    "$(OBJDIR):\n",
    "\tmkdir -p $(OBJDIR)\n",
    "backup:\n",
    "\tmkdir -p backup\n",
    "results:\n",
    "\tmkdir -p results\n",
    "setchmod:\n",
    "\tchmod +x *.sh\n",
    "\n",
    ".PHONY: clean\n",
    "\n",
    "clean:\n",
    "\trm -rf $(OBJS) $(EXEC) $(LIBNAMESO) $(APPNAMESO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install environment from the Makefile\n",
    "#note if you are on Colab Pro this works on a P100 GPU\n",
    "#if you are on Colab free, you may need to change the Makefile for the K80 GPU\n",
    "#this goes for any GPU, you need to change the Makefile to inform darknet which GPU you are running on.\n",
    "#note the Makefile above should work for you, if you need to tweak, try the below\n",
    "%cd /content/darknet/\n",
    "#!sed -i 's/OPENCV=0/OPENCV=1/g' Makefile\n",
    "#!sed -i 's/GPU=0/GPU=1/g' Makefile\n",
    "#!sed -i 's/CUDNN=0/CUDNN=1/g' Makefile\n",
    "!#sed -i \"s/ARCH= -gencode arch=compute_60,code=sm_60/ARCH= -gencode arch=compute_${compute_capability},code=sm_${compute_capability}/g\" Makefile\n",
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the newly released yolov4 ConvNet weights\n",
    "%cd /content/darknet\n",
    "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Custom Dataset for YOLOv4\n",
    "We'll use Roboflow to convert our dataset from any format to the YOLO Darknet format.\n",
    "\n",
    "To do so, create a free Roboflow account.\n",
    "Upload your images and their annotations (in any format: VOC XML, COCO JSON, TensorFlow CSV, etc).\n",
    "Apply preprocessing and augmentation steps you may like. We recommend at least auto-orient and a resize to 416x416. Generate your dataset.\n",
    "Export your dataset in the YOLO Darknet format.\n",
    "Copy your download link, and paste it below.\n",
    "See our blog post for greater detail.\n",
    "\n",
    "In this example, I used the open source BCCD Dataset. (You can fork it to your Roboflow account to follow along.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Projects\\\\Skripsi - AI - Social Distancing Detector\\\\alexeyb-darknet'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   890  100   890    0     0    786      0  0:00:01  0:00:01 --:--:--   787\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      " 42 5233k   42 2222k    0     0  1028k      0  0:00:05  0:00:02  0:00:03 2249k\n",
      " 68 5233k   68 3566k    0     0  1039k      0  0:00:05  0:00:03  0:00:02 1580k\n",
      " 77 5233k   77 4078k    0     0   971k      0  0:00:05  0:00:04  0:00:01 1348k\n",
      "100 5233k  100 5233k    0     0  1042k      0  0:00:05  0:00:05 --:--:-- 1360k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (6) Could not resolve host: ;\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:03 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:04 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:05 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:06 --:--:--     0curl: (6) Could not resolve host: unzip\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (6) Could not resolve host: roboflow.zip;\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0curl: (6) Could not resolve host: rm\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (6) Could not resolve host: roboflow.zip\n"
     ]
    }
   ],
   "source": [
    "#if you already have YOLO darknet format, you can skip this step\n",
    "# %cd /content/darknet\n",
    "# !curl -L [YOUR LINK HERE] > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
    "!curl -L \"https://app.roboflow.com/ds/LhFjQaWQTa?key=DBiUs0DYbG\" > roboflow.zip;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    " !unzip roboflow.zip; rm roboflow.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up training file directories for custom dataset\n",
    "# %cd /content/darknet/\n",
    "%cp train/_darknet.labels data/obj.names\n",
    "%mkdir data/obj\n",
    "#copy image and labels\n",
    "%cp train/*.jpg data/obj/\n",
    "%cp valid/*.jpg data/obj/\n",
    "\n",
    "%cp train/*.txt data/obj/\n",
    "%cp valid/*.txt data/obj/\n",
    "\n",
    "with open('data/obj.data', 'w') as out:\n",
    "  out.write('classes = 3\\n')\n",
    "  out.write('train = data/train.txt\\n')\n",
    "  out.write('valid = data/valid.txt\\n')\n",
    "  out.write('names = data/obj.names\\n')\n",
    "  out.write('backup = backup/')\n",
    "\n",
    "#write train file (just the image list)\n",
    "import os\n",
    "\n",
    "with open('data/train.txt', 'w') as out:\n",
    "  for img in [f for f in os.listdir('train') if f.endswith('jpg')]:\n",
    "    out.write('data/obj/' + img + '\\n')\n",
    "\n",
    "#write the valid file (just the image list)\n",
    "import os\n",
    "\n",
    "with open('data/valid.txt', 'w') as out:\n",
    "  for img in [f for f in os.listdir('valid') if f.endswith('jpg')]:\n",
    "    out.write('data/obj/' + img + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write Custom Training Config for YOLOv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/home/kevin'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/mnt/e/Projects/Skripsi - AI - Social Distancing Detector/alexeyb-darknet\nwriting config for a custom YOLOv4 detector detecting number of classes: 3\nfile is written!\n"
     ]
    }
   ],
   "source": [
    "#we build config dynamically based on number of classes\n",
    "#we build iteratively from base config files. This is the same file shape as cfg/yolo-obj.cfg\n",
    "# import os\n",
    "\n",
    "%cd '/mnt/e/Projects/Skripsi - AI - Social Distancing Detector/alexeyb-darknet/'\n",
    "\n",
    "def file_len(fname):\n",
    "  with open(fname) as f:\n",
    "    for i, l in enumerate(f):\n",
    "      pass\n",
    "  return i + 1\n",
    "\n",
    "num_classes = file_len('train/_darknet.labels')\n",
    "print(\"writing config for a custom YOLOv4 detector detecting number of classes: \" + str(num_classes))\n",
    "\n",
    "#Instructions from the darknet repo\n",
    "#change line max_batches to (classes*2000 but not less than number of training images, and not less than 6000), f.e. max_batches=6000 if you train for 3 classes\n",
    "#change line steps to 80% and 90% of max_batches, f.e. steps=4800,5400\n",
    "if os.path.exists('./cfg/custom-yolov4-detector.cfg'): os.remove('./cfg/custom-yolov4-detector.cfg')\n",
    "\n",
    "\n",
    "with open('./cfg/custom-yolov4-detector.cfg', 'a') as f:\n",
    "  f.write('[net]' + '\\n')\n",
    "  f.write('batch=64' + '\\n')\n",
    "  #####smaller subdivisions help the GPU run faster. 12 is optimal, but you might need to change to 24,36,64####\n",
    "  f.write('subdivisions=36' + '\\n')\n",
    "  f.write('width=416' + '\\n')\n",
    "  f.write('height=416' + '\\n')\n",
    "  f.write('channels=3' + '\\n')\n",
    "  f.write('momentum=0.949' + '\\n')\n",
    "  f.write('decay=0.0005' + '\\n')\n",
    "  f.write('angle=0' + '\\n')\n",
    "  f.write('saturation = 1.5' + '\\n')\n",
    "  f.write('exposure = 1.5' + '\\n')\n",
    "  f.write('hue = .1' + '\\n')\n",
    "  f.write('\\n')\n",
    "  f.write('learning_rate=0.001' + '\\n')\n",
    "  f.write('burn_in=1000' + '\\n')\n",
    "  ######you can adjust up and down to change training time#####\n",
    "  ##Darknet does iterations with batches, not epochs####\n",
    "  max_batches = num_classes*2000\n",
    "  #max_batches = 2000\n",
    "  f.write('max_batches=' + str(max_batches) + '\\n')\n",
    "  f.write('policy=steps' + '\\n')\n",
    "  steps1 = .8 * max_batches\n",
    "  steps2 = .9 * max_batches\n",
    "  f.write('steps='+str(steps1)+','+str(steps2) + '\\n')\n",
    "\n",
    "#Instructions from the darknet repo\n",
    "#change line classes=80 to your number of objects in each of 3 [yolo]-layers:\n",
    "#change [filters=255] to filters=(classes + 5)x3 in the 3 [convolutional] before each [yolo] layer, keep in mind that it only has to be the last [convolutional] before each of the [yolo] layers.\n",
    "\n",
    "  with open('cfg/yolov4-custom2.cfg', 'r') as f2:\n",
    "    content = f2.readlines()\n",
    "    for line in content:\n",
    "      f.write(line)    \n",
    "    num_filters = (num_classes + 5) * 3\n",
    "    f.write('filters='+str(num_filters) + '\\n')\n",
    "    f.write('activation=linear')\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('[yolo]' + '\\n')\n",
    "    f.write('mask = 0,1,2' + '\\n')\n",
    "    f.write('anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401' + '\\n')\n",
    "    f.write('classes=' + str(num_classes) + '\\n')\n",
    "\n",
    "  with open('cfg/yolov4-custom3.cfg', 'r') as f3:\n",
    "    content = f3.readlines()\n",
    "    for line in content:\n",
    "      f.write(line)    \n",
    "    num_filters = (num_classes + 5) * 3\n",
    "    f.write('filters='+str(num_filters) + '\\n')\n",
    "    f.write('activation=linear')\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('[yolo]' + '\\n')\n",
    "    f.write('mask = 3,4,5' + '\\n')\n",
    "    f.write('anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401' + '\\n')\n",
    "    f.write('classes=' + str(num_classes) + '\\n')\n",
    "\n",
    "  with open('cfg/yolov4-custom4.cfg', 'r') as f4:\n",
    "    content = f4.readlines()\n",
    "    for line in content:\n",
    "      f.write(line)    \n",
    "    num_filters = (num_classes + 5) * 3\n",
    "    f.write('filters='+str(num_filters) + '\\n')\n",
    "    f.write('activation=linear')\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('[yolo]' + '\\n')\n",
    "    f.write('mask = 6,7,8' + '\\n')\n",
    "    f.write('anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401' + '\\n')\n",
    "    f.write('classes=' + str(num_classes) + '\\n')\n",
    "    \n",
    "  with open('cfg/yolov4-custom5.cfg', 'r') as f5:\n",
    "    content = f5.readlines()\n",
    "    for line in content:\n",
    "      f.write(line)\n",
    "\n",
    "print(\"file is written!\")    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[net]\nbatch=64\nsubdivisions=36\nwidth=416\nheight=416\nchannels=3\nmomentum=0.949\ndecay=0.0005\nangle=0\nsaturation = 1.5\nexposure = 1.5\nhue = .1\n\nlearning_rate=0.001\nburn_in=1000\nmax_batches=6000\npolicy=steps\nsteps=4800.0,5400.0\nscales=.1,.1\n\n#cutmix=1\nmosaic=1\n\n#:104x104 54:52x52 85:26x26 104:13x13 for 416\n\n[convolutional]\nbatch_normalize=1\nfilters=32\nsize=3\nstride=1\npad=1\nactivation=mish\n\n# Downsample\n\n[convolutional]\nbatch_normalize=1\nfilters=64\nsize=3\nstride=2\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=64\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[route]\nlayers = -2\n\n[convolutional]\nbatch_normalize=1\nfilters=64\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=32\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=64\nsize=3\nstride=1\npad=1\nactivation=mish\n\n[shortcut]\nfrom=-3\nactivation=linear\n\n[convolutional]\nbatch_normalize=1\nfilters=64\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[route]\nlayers = -1,-7\n\n[convolutional]\nbatch_normalize=1\nfilters=64\nsize=1\nstride=1\npad=1\nactivation=mish\n\n# Downsample\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=3\nstride=2\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=64\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[route]\nlayers = -2\n\n[convolutional]\nbatch_normalize=1\nfilters=64\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=64\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=64\nsize=3\nstride=1\npad=1\nactivation=mish\n\n[shortcut]\nfrom=-3\nactivation=linear\n\n[convolutional]\nbatch_normalize=1\nfilters=64\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=64\nsize=3\nstride=1\npad=1\nactivation=mish\n\n[shortcut]\nfrom=-3\nactivation=linear\n\n[convolutional]\nbatch_normalize=1\nfilters=64\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[route]\nlayers = -1,-10\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=1\nstride=1\npad=1\nactivation=mish\n\n# Downsample\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=3\nstride=2\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[route]\nlayers = -2\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=3\nstride=1\npad=1\nactivation=mish\n\n[shortcut]\nfrom=-3\nactivation=linear\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=3\nstride=1\npad=1\nactivation=mish\n\n[shortcut]\nfrom=-3\nactivation=linear\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=3\nstride=1\npad=1\nactivation=mish\n\n[shortcut]\nfrom=-3\nactivation=linear\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=3\nstride=1\npad=1\nactivation=mish\n\n[shortcut]\nfrom=-3\nactivation=linear\n\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=3\nstride=1\npad=1\nactivation=mish\n\n[shortcut]\nfrom=-3\nactivation=linear\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=3\nstride=1\npad=1\nactivation=mish\n\n[shortcut]\nfrom=-3\nactivation=linear\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=3\nstride=1\npad=1\nactivation=mish\n\n[shortcut]\nfrom=-3\nactivation=linear\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=3\nstride=1\npad=1\nactivation=mish\n\n[shortcut]\nfrom=-3\nactivation=linear\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[route]\nlayers = -1,-28\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=1\nstride=1\npad=1\nactivation=mish\n\n# Downsample\n\n[convolutional]\nbatch_normalize=1\nfilters=512\nsize=3\nstride=2\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[route]\nlayers = -2\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=3\nstride=1\npad=1\nactivation=mish\n\n[shortcut]\nfrom=-3\nactivation=linear\n\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=3\nstride=1\npad=1\nactivation=mish\n\n[shortcut]\nfrom=-3\nactivation=linear\n\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=3\nstride=1\npad=1\nactivation=mish\n\n[shortcut]\nfrom=-3\nactivation=linear\n\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=3\nstride=1\npad=1\nactivation=mish\n\n[shortcut]\nfrom=-3\nactivation=linear\n\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=3\nstride=1\npad=1\nactivation=mish\n\n[shortcut]\nfrom=-3\nactivation=linear\n\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=3\nstride=1\npad=1\nactivation=mish\n\n[shortcut]\nfrom=-3\nactivation=linear\n\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=3\nstride=1\npad=1\nactivation=mish\n\n[shortcut]\nfrom=-3\nactivation=linear\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=3\nstride=1\npad=1\nactivation=mish\n\n[shortcut]\nfrom=-3\nactivation=linear\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[route]\nlayers = -1,-28\n\n[convolutional]\nbatch_normalize=1\nfilters=512\nsize=1\nstride=1\npad=1\nactivation=mish\n\n# Downsample\n\n[convolutional]\nbatch_normalize=1\nfilters=1024\nsize=3\nstride=2\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=512\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[route]\nlayers = -2\n\n[convolutional]\nbatch_normalize=1\nfilters=512\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=512\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=512\nsize=3\nstride=1\npad=1\nactivation=mish\n\n[shortcut]\nfrom=-3\nactivation=linear\n\n[convolutional]\nbatch_normalize=1\nfilters=512\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=512\nsize=3\nstride=1\npad=1\nactivation=mish\n\n[shortcut]\nfrom=-3\nactivation=linear\n\n[convolutional]\nbatch_normalize=1\nfilters=512\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=512\nsize=3\nstride=1\npad=1\nactivation=mish\n\n[shortcut]\nfrom=-3\nactivation=linear\n\n[convolutional]\nbatch_normalize=1\nfilters=512\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[convolutional]\nbatch_normalize=1\nfilters=512\nsize=3\nstride=1\npad=1\nactivation=mish\n\n[shortcut]\nfrom=-3\nactivation=linear\n\n[convolutional]\nbatch_normalize=1\nfilters=512\nsize=1\nstride=1\npad=1\nactivation=mish\n\n[route]\nlayers = -1,-16\n\n[convolutional]\nbatch_normalize=1\nfilters=1024\nsize=1\nstride=1\npad=1\nactivation=mish\n\n##########################\n\n[convolutional]\nbatch_normalize=1\nfilters=512\nsize=1\nstride=1\npad=1\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nsize=3\nstride=1\npad=1\nfilters=1024\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nfilters=512\nsize=1\nstride=1\npad=1\nactivation=leaky\n\n### SPP ###\n[maxpool]\nstride=1\nsize=5\n\n[route]\nlayers=-2\n\n[maxpool]\nstride=1\nsize=9\n\n[route]\nlayers=-4\n\n[maxpool]\nstride=1\nsize=13\n\n[route]\nlayers=-1,-3,-5,-6\n### End SPP ###\n\n[convolutional]\nbatch_normalize=1\nfilters=512\nsize=1\nstride=1\npad=1\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nsize=3\nstride=1\npad=1\nfilters=1024\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nfilters=512\nsize=1\nstride=1\npad=1\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=1\nstride=1\npad=1\nactivation=leaky\n\n[upsample]\nstride=2\n\n[route]\nlayers = 85\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=1\nstride=1\npad=1\nactivation=leaky\n\n[route]\nlayers = -1, -3\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=1\nstride=1\npad=1\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nsize=3\nstride=1\npad=1\nfilters=512\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=1\nstride=1\npad=1\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nsize=3\nstride=1\npad=1\nfilters=512\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=1\nstride=1\npad=1\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=1\nstride=1\npad=1\nactivation=leaky\n\n[upsample]\nstride=2\n\n[route]\nlayers = 54\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=1\nstride=1\npad=1\nactivation=leaky\n\n[route]\nlayers = -1, -3\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=1\nstride=1\npad=1\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nsize=3\nstride=1\npad=1\nfilters=256\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=1\nstride=1\npad=1\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nsize=3\nstride=1\npad=1\nfilters=256\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nfilters=128\nsize=1\nstride=1\npad=1\nactivation=leaky\n\n##########################\n\n[convolutional]\nbatch_normalize=1\nsize=3\nstride=1\npad=1\nfilters=256\nactivation=leaky\n\n[convolutional]\nsize=1\nstride=1\npad=1\nfilters=24\nactivation=linear\n\n[yolo]\nmask = 0,1,2\nanchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401\nclasses=3\nnum=9\njitter=.3\nignore_thresh = .7\ntruth_thresh = 1\nscale_x_y = 1.2\niou_thresh=0.213\ncls_normalizer=1.0\niou_normalizer=0.07\niou_loss=ciou\nnms_kind=greedynms\nbeta_nms=0.6\nmax_delta=5\n\n\n[route]\nlayers = -4\n\n[convolutional]\nbatch_normalize=1\nsize=3\nstride=2\npad=1\nfilters=256\nactivation=leaky\n\n[route]\nlayers = -1, -16\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=1\nstride=1\npad=1\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nsize=3\nstride=1\npad=1\nfilters=512\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=1\nstride=1\npad=1\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nsize=3\nstride=1\npad=1\nfilters=512\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nfilters=256\nsize=1\nstride=1\npad=1\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nsize=3\nstride=1\npad=1\nfilters=512\nactivation=leaky\n\n[convolutional]\nsize=1\nstride=1\npad=1\nfilters=24\nactivation=linear\n\n[yolo]\nmask = 3,4,5\nanchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401\nclasses=3\nnum=9\njitter=.3\nignore_thresh = .7\ntruth_thresh = 1\nscale_x_y = 1.1\niou_thresh=0.213\ncls_normalizer=1.0\niou_normalizer=0.07\niou_loss=ciou\nnms_kind=greedynms\nbeta_nms=0.6\nmax_delta=5\n\n\n[route]\nlayers = -4\n\n[convolutional]\nbatch_normalize=1\nsize=3\nstride=2\npad=1\nfilters=512\nactivation=leaky\n\n[route]\nlayers = -1, -37\n\n[convolutional]\nbatch_normalize=1\nfilters=512\nsize=1\nstride=1\npad=1\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nsize=3\nstride=1\npad=1\nfilters=1024\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nfilters=512\nsize=1\nstride=1\npad=1\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nsize=3\nstride=1\npad=1\nfilters=1024\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nfilters=512\nsize=1\nstride=1\npad=1\nactivation=leaky\n\n[convolutional]\nbatch_normalize=1\nsize=3\nstride=1\npad=1\nfilters=1024\nactivation=leaky\n\n[convolutional]\nsize=1\nstride=1\npad=1\nfilters=24\nactivation=linear\n\n[yolo]\nmask = 6,7,8\nanchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401\nclasses=3\nnum=9\njitter=.3\nignore_thresh = .7\ntruth_thresh = 1\nrandom=1\nscale_x_y = 1.05\niou_thresh=0.213\ncls_normalizer=1.0\niou_normalizer=0.07\niou_loss=ciou\nnms_kind=greedynms\nbeta_nms=0.6\nmax_delta=5\n"
     ]
    }
   ],
   "source": [
    "#here is the file that was just written. \n",
    "#you may consider adjusting certain things\n",
    "\n",
    "#like the number of subdivisions 64 runs faster but Colab GPU may not be big enough\n",
    "#if Colab GPU memory is too small, you will need to adjust subdivisions to 16\n",
    "%cat cfg/custom-yolov4-detector.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "total 967825\ndrwxrwxrwx 1 kevin kevin       512 Dec 21 23:39  \u001b[0m\u001b[34;42m3rdparty\u001b[0m/\n-rwxrwxrwx 1 kevin kevin     21131 Dec 21 23:39  \u001b[01;32mCMakeLists.txt\u001b[0m*\ndrwxrwxrwx 1 kevin kevin       512 Jan 11 01:03 \u001b[34;42m'COCO prequisites files'\u001b[0m/\n-rwxrwxrwx 1 kevin kevin      1363 Dec 21 23:39  \u001b[01;32mDarknetConfig.cmake.in\u001b[0m*\n-rwxrwxrwx 1 kevin kevin       515 Dec 21 23:39  \u001b[01;32mLICENSE\u001b[0m*\n-rwxrwxrwx 1 kevin kevin      5938 Dec 21 23:39  \u001b[01;32mMakefile\u001b[0m*\n-rwxrwxrwx 1 kevin kevin     58148 Dec 21 23:39  \u001b[01;32mREADME.md\u001b[0m*\ndrwxrwxrwx 1 kevin kevin       512 Jan  7 01:08  \u001b[34;42m__pycache__\u001b[0m/\n-rwxrwxrwx 1 kevin kevin  17856000 Dec 21 02:29  \u001b[01;32mavcodec-58.dll\u001b[0m*\n-rwxrwxrwx 1 kevin kevin   2966528 Dec 21 02:29  \u001b[01;32mavformat-58.dll\u001b[0m*\n-rwxrwxrwx 1 kevin kevin    756224 Dec 21 02:29  \u001b[01;32mavutil-56.dll\u001b[0m*\n-rwxrwxrwx 1 kevin kevin       114 Jan  7 00:26  \u001b[01;32mbad.list\u001b[0m*\ndrwxrwxrwx 1 kevin kevin       512 Dec 21 23:39  \u001b[34;42mbuild\u001b[0m/\n-rwxrwxrwx 1 kevin kevin      8453 Dec 21 23:39  \u001b[01;32mbuild.ps1\u001b[0m*\n-rwxrwxrwx 1 kevin kevin      2044 Dec 21 23:39  \u001b[01;32mbuild.sh\u001b[0m*\ndrwxrwxrwx 1 kevin kevin       512 Dec 21 23:41  \u001b[34;42mbuild_release\u001b[0m/\ndrwxrwxrwx 1 kevin kevin       512 Dec 22 00:21  \u001b[34;42mbuild_win_release\u001b[0m/\ndrwxrwxrwx 1 kevin kevin       512 Jan 12 00:56  \u001b[34;42mcfg\u001b[0m/\ndrwxrwxrwx 1 kevin kevin       512 Dec 21 23:40  \u001b[34;42mcmake\u001b[0m/\n-rwxrwxrwx 1 kevin kevin 412253696 May  9  2019  \u001b[01;32mcudnn64_7.dll\u001b[0m*\n-rwxrwxrwx 1 kevin kevin   3236864 Dec 22 00:20  \u001b[01;32mdarknet.dll\u001b[0m*\n-rwxrwxrwx 1 kevin kevin   2719744 Dec 22 00:21  \u001b[01;32mdarknet.exe\u001b[0m*\n-rwxrwxrwx 1 kevin kevin     20282 Dec 22 00:20  \u001b[01;32mdarknet.lib\u001b[0m*\n-rwxrwxrwx 1 kevin kevin     10438 Jan  7 01:19  \u001b[01;32mdarknet.py\u001b[0m*\n-rwxrwxrwx 1 kevin kevin      9467 Dec 21 23:40  \u001b[01;32mdarknet_images.py\u001b[0m*\n-rwxrwxrwx 1 kevin kevin      5316 Dec 21 23:40  \u001b[01;32mdarknet_video.py\u001b[0m*\n-rwxrwxrwx 1 kevin kevin      8847 Jan  7 01:08  \u001b[01;32mdarknet_video_mod.py\u001b[0m*\ndrwxrwxrwx 1 kevin kevin       512 Jan 12 00:25  \u001b[34;42mdata\u001b[0m/\n-rwxrwxrwx 1 kevin kevin       110 Dec 21 23:40  \u001b[01;32mimage_yolov3.sh\u001b[0m*\n-rwxrwxrwx 1 kevin kevin       110 Dec 21 23:40  \u001b[01;32mimage_yolov4.sh\u001b[0m*\ndrwxrwxrwx 1 kevin kevin       512 Dec 22 00:21  \u001b[34;42minclude\u001b[0m/\n-rwxrwxrwx 1 kevin kevin    551936 Dec 21 02:46  \u001b[01;32mjpeg62.dll\u001b[0m*\n-rwxrwxrwx 1 kevin kevin       345 Dec 21 23:40  \u001b[01;32mjson_mjpeg_streams.sh\u001b[0m*\n-rwxrwxrwx 1 kevin kevin    192512 Dec 21 02:48  \u001b[01;32mlibpng16.dll\u001b[0m*\n-rwxrwxrwx 1 kevin kevin    155136 Dec 21 02:47  \u001b[01;32mlzma.dll\u001b[0m*\n-rwxrwxrwx 1 kevin kevin       159 Dec 21 23:40  \u001b[01;32mnet_cam_v3.sh\u001b[0m*\n-rwxrwxrwx 1 kevin kevin       159 Dec 21 23:40  \u001b[01;32mnet_cam_v4.sh\u001b[0m*\n-rwxrwxrwx 1 kevin kevin   2171904 Dec 21 03:08  \u001b[01;32mopencv_calib3d.dll\u001b[0m*\n-rwxrwxrwx 1 kevin kevin   3713024 Dec 21 03:02  \u001b[01;32mopencv_core.dll\u001b[0m*\n-rwxrwxrwx 1 kevin kevin    768000 Dec 21 03:07  \u001b[01;32mopencv_features2d.dll\u001b[0m*\n-rwxrwxrwx 1 kevin kevin    407552 Dec 21 03:02  \u001b[01;32mopencv_flann.dll\u001b[0m*\n-rwxrwxrwx 1 kevin kevin    184320 Dec 21 03:05  \u001b[01;32mopencv_highgui.dll\u001b[0m*\n-rwxrwxrwx 1 kevin kevin    373760 Dec 21 03:05  \u001b[01;32mopencv_imgcodecs.dll\u001b[0m*\n-rwxrwxrwx 1 kevin kevin   5005312 Dec 21 03:05  \u001b[01;32mopencv_imgproc.dll\u001b[0m*\n-rwxrwxrwx 1 kevin kevin    556544 Dec 21 03:09  \u001b[01;32mopencv_video.dll\u001b[0m*\n-rwxrwxrwx 1 kevin kevin    496640 Dec 21 03:05  \u001b[01;32mopencv_videoio.dll\u001b[0m*\n-rwxrwxrwx 1 kevin kevin    127025 Jan  7 00:27  \u001b[01;32mpredictions.jpg\u001b[0m*\n-rwxrwxrwx 1 kevin kevin    102400 Dec 21 03:09  \u001b[01;32mpthreadVC3.dll\u001b[0m*\ndrwxrwxrwx 1 kevin kevin       512 Dec 21 23:40  \u001b[34;42mresults\u001b[0m/\n-rwxrwxrwx 1 kevin kevin   5358775 Jan 11 22:58  \u001b[01;32mroboflow.zip\u001b[0m*\ndrwxrwxrwx 1 kevin kevin       512 Dec 21 23:40  \u001b[34;42mscripts\u001b[0m/\ndrwxrwxrwx 1 kevin kevin       512 Dec 22 00:21  \u001b[34;42mshare\u001b[0m/\ndrwxrwxrwx 1 kevin kevin       512 Dec 22 00:20  \u001b[34;42msrc\u001b[0m/\n-rwxrwxrwx 1 kevin kevin    183808 Dec 21 02:29  \u001b[01;32mswresample-3.dll\u001b[0m*\n-rwxrwxrwx 1 kevin kevin    718848 Dec 21 02:29  \u001b[01;32mswscale-5.dll\u001b[0m*\ndrwxrwxrwx 1 kevin kevin       512 Jan 11 21:32  \u001b[34;42mtest\u001b[0m/\n-rwxrwxrwx 1 kevin kevin    431616 Dec 21 02:56  \u001b[01;32mtiff.dll\u001b[0m*\ndrwxrwxrwx 1 kevin kevin       512 Jan 11 21:32  \u001b[34;42mtrain\u001b[0m/\n-rwxrwxrwx 1 kevin kevin    135168 Dec 22 00:21  \u001b[01;32muselib.exe\u001b[0m*\ndrwxrwxrwx 1 kevin kevin       512 Jan 11 21:32  \u001b[34;42mvalid\u001b[0m/\n-rwxrwxrwx 1 kevin kevin  23596532 Dec 21 03:24  \u001b[01;32mvideo1.mp4\u001b[0m*\n-rwxrwxrwx 1 kevin kevin  73179477 Dec 22 20:51  \u001b[01;32mvideo2.mp4\u001b[0m*\n-rwxrwxrwx 1 kevin kevin   4213397 Dec 22 20:57  \u001b[01;32mvideo3.mp4\u001b[0m*\n-rwxrwxrwx 1 kevin kevin       108 Dec 21 23:40  \u001b[01;32mvideo_yolov3.sh\u001b[0m*\n-rwxrwxrwx 1 kevin kevin       108 Dec 21 23:40  \u001b[01;32mvideo_yolov4.sh\u001b[0m*\n-rwxrwxrwx 1 kevin kevin    515584 Dec 21 02:48  \u001b[01;32mwebp.dll\u001b[0m*\n-rwxrwxrwx 1 kevin kevin 170038676 Jan 10 20:57  \u001b[01;32myolov4.conv.137\u001b[0m*\n-rwxrwxrwx 1 kevin kevin     46641 Jan 12 01:06  \u001b[01;32myolov4.ipynb\u001b[0m*\n-rwxrwxrwx 1 kevin kevin 257717640 Dec  3 23:36  \u001b[01;32myolov4.weights\u001b[0m*\n-rwxrwxrwx 1 kevin kevin     85504 Dec 21 02:47  \u001b[01;32mzlib1.dll\u001b[0m*\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "%ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'darknet.exe detector train ./data/obj.data ./cfg/custom-yolov4-detector.cfg ./yolov4.conv.137 -dont_show -map'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-c969042974ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# subprocess.run(r\"darknet.exe detector demo ./cfg/coco.data ./cfg/yolov4.cfg ./yolov4.weights video3.mp4 -i 0 -thresh 0.25\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"darknet.exe detector train ./data/obj.data ./cfg/custom-yolov4-detector.cfg ./yolov4.conv.137 -dont_show -map\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#If you get CUDA out of memory adjust subdivisions above!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stderr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    852\u001b[0m                             encoding=encoding, errors=errors)\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m    855\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m                                 \u001b[0mstartupinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreationflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1700\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merrno_num\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m                         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'darknet.exe detector train ./data/obj.data ./cfg/custom-yolov4-detector.cfg ./yolov4.conv.137 -dont_show -map'"
     ]
    }
   ],
   "source": [
    "# !./darknet detector train data/obj.data cfg/custom-yolov4-detector.cfg yolov4.conv.137 -dont_show -map\n",
    "# %run darknet.exe detector train data/obj.data cfg/custom-yolov4-detector.cfg yolov4.conv.137 -dont_show -map\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# program=\"E://Projects//Skripsi - AI - Social Distancing Detector//alexeyb-darknet//darknet.exe\"\n",
    "program='/mnt/e/Projects/Skripsi - AI - Social Distancing Detector/alexeyb-darknet/darknet.exe'\n",
    "# program='darknet.exe'\n",
    "arguments=('detector train data/obj.data cfg/custom-yolov4-detector.cfg yolov4.conv.137 -dont_show -map')\n",
    "# subprocess.call([program, arguments])\n",
    "\n",
    "# subprocess.run(r\"darknet.exe detector demo ./cfg/coco.data ./cfg/yolov4.cfg ./yolov4.weights video3.mp4 -i 0 -thresh 0.25\")\n",
    "subprocess.run(r\"darknet.exe detector train ./data/obj.data ./cfg/custom-yolov4-detector.cfg ./yolov4.conv.137 -dont_show -map\")\n",
    "\n",
    "#If you get CUDA out of memory adjust subdivisions above!\n",
    "#adjust max batches down for shorter training above"
   ]
  },
  {
   "source": [
    "Infer Custom Objects with Saved YOLOv4 Weights"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define utility function\n",
    "def imShow(path):\n",
    "  import cv2\n",
    "  import matplotlib.pyplot as plt\n",
    "  %matplotlib inline\n",
    "\n",
    "  image = cv2.imread(path)\n",
    "  height, width = image.shape[:2]\n",
    "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "  fig = plt.gcf()\n",
    "  fig.set_size_inches(18, 10)\n",
    "  plt.axis(\"off\")\n",
    "  #plt.rcParams['figure.figsize'] = [10, 5]\n",
    "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/home/kevin'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/mnt/e/Projects/Skripsi - AI - Social Distancing Detector/alexeyb-darknet\ncustom-yolov4-detector_1000.weights  custom-yolov4-detector_6000.weights\ncustom-yolov4-detector_2000.weights  custom-yolov4-detector_best.weights\ncustom-yolov4-detector_3000.weights  custom-yolov4-detector_final.weights\ncustom-yolov4-detector_4000.weights  custom-yolov4-detector_last.weights\ncustom-yolov4-detector_5000.weights\n"
     ]
    }
   ],
   "source": [
    "#check if weigths have saved yet\n",
    "#backup houses the last weights for our detector\n",
    "#(file yolo-obj_last.weights will be saved to the build\\darknet\\x64\\backup\\ for each 100 iterations)\n",
    "#(file yolo-obj_xxxx.weights will be saved to the build\\darknet\\x64\\backup\\ for each 1000 iterations)\n",
    "#After training is complete - get result yolo-obj_final.weights from path build\\darknet\\x64\\bac\n",
    "%cd '/mnt/e/Projects/Skripsi - AI - Social Distancing Detector/alexeyb-darknet/'\n",
    "!ls backup\n",
    "#if it is empty you haven't trained for long enough yet, you need to train for at least 100 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coco.names is hardcoded somewhere in the detector\n",
    "%cp data/obj.names data/coco.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'darknet.exe detect cfg/custom-yolov4-detector.cfg backup/custom-yolov4-detector_best.weights {img_path} -dont-show'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7faf05c4b8d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# arguments=('detector train data/obj.data cfg/custom-yolov4-detector.cfg yolov4.conv.137 -dont_show -map')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# subprocess.call([program, arguments])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"darknet.exe detect cfg/custom-yolov4-detector.cfg backup/custom-yolov4-detector_best.weights {img_path} -dont-show\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# custom-yolov4-detector_best.weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stderr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    852\u001b[0m                             encoding=encoding, errors=errors)\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m    855\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m                                 \u001b[0mstartupinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreationflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1700\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merrno_num\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m                         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'darknet.exe detect cfg/custom-yolov4-detector.cfg backup/custom-yolov4-detector_best.weights {img_path} -dont-show'"
     ]
    }
   ],
   "source": [
    "\n",
    "# import os\n",
    "#/test has images that we can test our detector on\n",
    "test_images = [f for f in os.listdir('test') if f.endswith('.jpg')]\n",
    "import random\n",
    "img_path = \"test/\" + random.choice(test_images);\n",
    "\n",
    "#test out our detector!\n",
    "# !./darknet detect cfg/custom-yolov4-detector.cfg backup/custom-yolov4-detector_last.weights {img_path} -dont-show\n",
    "!darknet.exe detect cfg/custom-yolov4-detector.cfg backup/custom-yolov4-detector_best.weights test/BloodImage_00038_jpg.rf.b727e34a88ace0a31547ba24adafb2d2.jpg -dont-show\n",
    "!darknet.exe detect cfg/custom-yolov4-detector.cfg backup/custom-yolov4-detector_best.weights test/BloodImage_00284_jpg.rf.a4b22db0c95c3fbc123777e01aeff2a2.jpg -dont-show\n",
    "\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# program=\"E://Projects//Skripsi - AI - Social Distancing Detector//alexeyb-darknet//darknet.exe\"\n",
    "# program='/mnt/e/Projects/Skripsi - AI - Social Distancing Detector/alexeyb-darknet/darknet.exe'\n",
    "# program='darknet.exe'\n",
    "# arguments=('detector train data/obj.data cfg/custom-yolov4-detector.cfg yolov4.conv.137 -dont_show -map')\n",
    "# subprocess.call([program, arguments])\n",
    "subprocess.run(r\"darknet.exe detect cfg/custom-yolov4-detector.cfg backup/custom-yolov4-detector_best.weights {img_path} -dont-show\")\n",
    "\n",
    "# custom-yolov4-detector_best.weights\n",
    "# imShow('predictions.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}